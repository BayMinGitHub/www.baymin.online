{"meta":{"title":"兔子的个人小站","subtitle":null,"description":"博客,游戏","author":"BayMin","url":"https://39.97.115.194","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-05-09T09:05:02.330Z","updated":"2019-05-09T09:05:02.330Z","comments":true,"path":"404.html","permalink":"https://39.97.115.194/404.html","excerpt":"","text":"404 Not Found 很抱歉，您访问的页面不存在可能是输入地址有误或该地址已被删除"},{"title":"朋友","date":"2019-05-10T07:49:40.999Z","updated":"2019-05-10T07:49:40.999Z","comments":true,"path":"friends/index.html","permalink":"https://39.97.115.194/friends/index.html","excerpt":"","text":"欢迎各位大佬留言互换友链，格式如下：名称： BayMin网址： https://www.baymin.online头像： https://www.baymin.online/img/avatar.png标签： Java,数据库"},{"title":"","date":"2019-05-09T08:17:02.191Z","updated":"2019-05-09T08:17:02.191Z","comments":true,"path":"mylist/index.html","permalink":"https://39.97.115.194/mylist/index.html","excerpt":"","text":""},{"title":"关于小站","date":"2019-05-09T03:22:57.714Z","updated":"2019-05-09T03:22:57.714Z","comments":true,"path":"about/index.html","permalink":"https://39.97.115.194/about/index.html","excerpt":"","text":"本站开始创建于2019年5月5日。"},{"title":"所有标签","date":"2019-05-09T02:45:49.156Z","updated":"2019-05-09T02:45:49.156Z","comments":true,"path":"tags/index.html","permalink":"https://39.97.115.194/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-05-10T07:50:10.397Z","updated":"2019-05-10T07:50:10.397Z","comments":true,"path":"categories/index.html","permalink":"https://39.97.115.194/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux系统下搭建饥荒专用服务器（阿里云主机）","slug":"Linux系统下搭建饥荒专用服务器","date":"2019-04-24T08:29:00.000Z","updated":"2019-05-16T03:28:57.409Z","comments":true,"path":"2019/04/24/Linux系统下搭建饥荒专用服务器/","link":"","permalink":"https://39.97.115.194/2019/04/24/Linux系统下搭建饥荒专用服务器/","excerpt":"从零开始的饥荒专用服务器教程~~~","text":"从零开始的饥荒专用服务器教程~~~ 前言经常玩单机游戏的玩家都会知道，在联机过程中房主的网络状态和电脑性能影响着整个房间中玩家的游戏体验，在房主网络状态差或电脑性能低的时候，经常会出现卡顿，丢包甚至掉线的情况。这是由于在房主开游戏的时候，会在其电脑本地启动一个服务器端，然后玩家的游戏客户端都与这个服务器端连接，进行联机游戏，当房主电脑性能不足或者网络波动时，必定会影响整个服务器中的玩家体验。 1.准备① 用来买云主机的 Money … ( 嗯 … 钱是很重要的 .. 不过可以考虑一下学生机 ,如果还是学生的话 ) ② 一台可以上网的电脑 ( 废话 ) ③ SSH连接工具 ( 推荐Xshell,免费版即可，提取码：idvz ) 2.购买云主机此处使用阿里云主机作为示例。 首先打开阿里云官网，注册…登陆…实名制之类的东西，然后打开购买页面 ： 此处应有图片…. 1 地域：服务器地区尽量选择离你较近的地域，可以有效降低延迟。 实例：一定不要因为便宜而选突发性实例，这个规格的云主机每天只有2个多小时是满性能的，其他情况下都是超级卡的状态 ( 显然我是买过的…😭 ) 镜像：选择CentOS 7.6 64位 ( 如果会Linux相关知识，系统可自己选择 ) 存储：默认40G，完全够用了 点击下一步，进入网络和安全组配置： 此处应有图片… 2 网络：默认 公网带宽：选择按固定带宽1M ( 多人可以考虑2M，如果用量不大可以选择按量付费，不过不确定一个月的具体流量 ) 安全组：默认 点击下一步，进入系统配置： 登录凭证：选择自定义密码，输入登录密码 ( 以后可以在控制台重置密码 ) 其他默认，然后确认订单，付款。 关于服务器配置的选择，贴一张官网的图： 此处应有图片…. 3 意思就是： ① 一个玩家需要8Kb/s的上传带宽 ( 云主机的宽带通常就是指的上传带宽，这个很容易满足 ) ② 一个玩家大约需要65M内存 ( 内存是需要重视的问题，通常玩饥荒都会开启两个世界：一个地上，一个地下。因此在计算内存的时候，如果你选择开启两个世界，那么这个数据需要乘上2。而且这个是指不开任何Mod的情况下，如果是大型Mod，内存占用是很可怕的。之前试过一次智能敌对，一个世界的进程能吃1G的内存 ) ③ 不是很清楚它说的CPU是N/A是任意的意思么，可是实际上后期世界中的生物越来越多的情况下，CPU特别容易爆 ( 推荐安装服务器清理Mod ) ④ 需要的环境 参考 : 我使用的是1核2G2M带宽的服务器 ,一年费用是1000+，在装有服务器清理Mod的情况下，正常6人玩到200多天是没什么问题的，不过在青蛙雨和蜘蛛区的时候还是会很卡。( 吐槽一下：垃圾游戏渣优化，以前弄求生之路服务器的时候，完全不需要考虑内存的问题，饥荒这种贴图游戏实在是太吃内存了…😒 ) 3.配置并连接云主机付款后，过一分钟左右就可以在控制台看到云主机了，显示的都是一些基本信息，记录下公网IP地址。然后按照下图进入安全组配置： 此处应用图片。。。 4 点击配置规则：( 饥荒服务器默认端口为10999和10998，因此需要开启这两个端口 ) 此处应有图片… 5 此处应有图片… 6 打开Xshell工具，使用快捷键ALT+N新建连接，如下图 ( 也可以点击 -&gt; 文件 -&gt; 新建 )： 此处应有图片… 7 此处应有图片… 8 点击连接，下面的提示点击确定，进入下面的界面就表示连接成功： 此处应有图片… 9 4.下载并安装游戏接下来就是操作Linux系统了，下面命令按行敲入窗口中，按回车键执行。 首先更新yum ( Linux系统中安装软件包的工具 ) : 12yum updateyum upgrade -y 安装游戏运行环境和常用工具 1yum install glibc.i686 libstdc++.i686 libcurl.i686 vim screen -y 创建steam用户 12345useradd steam su steamcd ~mkdir steamcmdcd steamcmd 下载并解压Steam的Linux客户端steamcmd 12wget https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gztar -zxvf steamcmd_linux.tar.gz 启动Steam客户端，并开始下载饥荒 ( 饥荒专用服务器ID为 343050 ) 1./steamcmd.sh +login anonymous +force_install_dir /home/dst +app_update 343050 validate +quit 下载完毕后 ( 大概十分钟左右 )，先启动一次服务器，验证是否缺失依赖 12cd /home/steam/dst/bin~/dst/bin/dontstarve_dedicated_server_nullrenderer -cluster MyDediServer -shard Master 此时可能会报找不到libcurl-gnutls.so.4，解决方法为将该依赖库复制到饥荒游戏文件夹中： 1cp /usr/lib/libcurl.so.4 ~/dst/bin/lib32/libcurl-gnutls.so.4 这里可能会有其他依赖包的缺失问题，解决办法即是将依赖复制到饥荒游戏文件夹中。 正常启动后，按Ctrl+C即可关闭服务器，也可以使用控制台命令c_shutdown()。 PS：饥荒服务器控制台指令自行百度。 5.存档配置在存档配置之前，我们现在电脑上打开饥荒联机版游戏，进入主界面，点击下面的官网按钮，查看个人ID和个人服务器的token，如下： 12个人ID: KU_uG******服务器token: pds-g^KU_uGVY9tdU^M***************************Sdsg50g4A6jg= 此处应有图片… 10 11 12 饥荒默认存档位置在用户目录中.kiel文件夹中 ( ~/.kiel/DoNotStarveTogether)，由于我们在上面的启动命令中增加了-cluster参数，因此会在该文件夹中自动创建名为MyDediServer的存档文件夹，如果不指定该参数，则会自动生成Cluster_1的文件夹。由于饥荒服务器直接配置文件太过复杂，这里推荐使用存档替换的方式。 首先在个人电脑上启动游戏，创建一个新世界 ( 此处记住服务器栏位1~5 ) ，自定义自己的世界配置和Mod配置，启动世界后等到选人界面时退出 此处应有图片… 13 在游戏首页点击存档图标，进入本地存档目录，按照你刚才的栏位找到名为Cluster_[栏位]的文件夹，即为刚才创建的世界存档，复制当前文档路径，例如：F:\\我的文档\\Klei\\DoNotStarveTogether\\Cluster_1 此处应有图片… 14 打开Xftp工具，直接点击下图所示图标即可 此处应有图片… 15 左边为本地文件目录，右边为远程服务器文件目录 此处应有图片… 16 在左边粘贴刚才复制的文档路径，回车进入；右边输入服务器存档目录即 /home/steam/.klei/DoNotStarveTogether/MyDediServer，回车进入 此处应有图片… 17 文件对应说明： ① Master 文件夹为主世界即地面世界存档及配置 ② Caves 文件夹为洞穴世界存档及配置 ③ cluser.ini 文件为服务器信息，世界名称，密码等 ④ cluster_token.txt 为服务器 token ⑤ Master 和 Caves 中共有的 : 1234567backup -&gt; 服务器日志及聊天日志存档save -&gt;存档文件夹sever_chat_log.txt -&gt; 服务器此次启动中玩家的聊天内容server_log.txt -&gt; 服务器日志server.ini -&gt; 世界的配置信息，端口等leveldataoverride.lua-&gt;世界配置文件，即为世界详细配置，可以直接对其更改，来完成对世界的自定义modoverrides.lua -&gt; Mod配置文件，可以对其修改完成服务器Mod配置 直接选中左侧所有文件及文件夹，拖拽至右侧，选择全部覆盖，等待文件全部传输至服务器即可关闭。然后再次回到Xshell窗口 ( 由于创建steam用户时没有增加密码，因此上传文件时默认使用的是root用户，此时需要先更改文件所有者 ) 123exitchown -R steam:steam /home/steam su steam 再进入存档文件夹，修改服务器token： 123456cd /home/steam/.klei/DoNotStarveTogether/MyDediServer# 编辑cluster_token.txtvim cluster_token.txt# 此时按i进入编辑模式，在文件中输入之前获取的服务器tokenpds-g^KU_uGVY9tdU^M***************************Sdsg50g4A6jg=# 编辑完成，按ESC，输入:wq 回车，即为保存并退出 编辑管理员列表 ( 非必须 ) : 12345# 编辑adminlist.txt管理员列表，输入你想添加的玩家ID（类似于之前获取的个人ID）由于服务器token所有者默认拥有管理员权限，因此不需要添加自己的ID，此处仅做为参考vim adminlist.txt# 输入KU_uG******# 编辑完成，按ESC，输入:wq 回车，即为保存并退出 编辑黑名单列表 ( 非必须 ) : 1234vim blocklist.txt# 输入黑名单玩家IDxxxxxxx# 编辑完成，按ESC，输入:wq 回车，即为保存并退出 6.MOD下载及使用Mod的配置文件即为上面所说的modoverrides.lua，使用编辑页面打开： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061return &#123; [\"workshop-1160616621\"]=&#123; configuration_options=&#123; Language=\"def\", Ownership=true, Travel_Cost=32 &#125;, enabled=false &#125;, [\"workshop-1216718131\"]=&#123; configuration_options=&#123; clean=true, lang=true, stack=true &#125;, enabled=true &#125;, [\"workshop-362175979\"]=&#123; configuration_options=&#123; [\"Draw over FoW\"]=\"disabled\" &#125;, enabled=true &#125;, [\"workshop-378160973\"]=&#123; configuration_options=&#123; ENABLEPINGS=true, FIREOPTIONS=2, OVERRIDEMODE=false, SHAREMINIMAPPROGRESS=true, SHOWFIREICONS=true, SHOWPLAYERICONS=true, SHOWPLAYERSOPTIONS=2 &#125;, enabled=true &#125;, [\"workshop-703758203\"]=&#123; configuration_options=&#123; &#125;, enabled=true &#125;, [\"workshop-804317397\"]=&#123; configuration_options=&#123; buffgo=false, fhl_cos=0.05, fhl_hjopen=false, likeornot=false, openli=false, openlight=false, zzj_cankanshu=false, zzj_canuseashammer=false, zzj_canuseasshovel=false, zzj_canwakuang=false, zzj_finiteuses=210, zzj_fireopen=false, zzj_pre=1 &#125;, enabled=true &#125;,-- Show Me [\"workshop-666155465\"]=&#123; configuration_options=&#123; food_estimation=-1, food_order=0, food_style=0, lang=\"chs\", show_food_units=-1 &#125;, enabled=true &#125;,-- 复活 [\"workshop-462434129\"]=&#123; configuration_options=&#123; MOD_RESTART_ALLOW_KILL=false, MOD_RESTART_ALLOW_RESTART=true, MOD_RESTART_ALLOW_RESURRECT=true, MOD_RESTART_CD_KILL=100, MOD_RESTART_CD_RESTART=100, MOD_RESTART_CD_RESURRECT=100, MOD_RESTART_FORCE_DROP_MODE=1, MOD_RESTART_IGNORING_ADMIN=true, MOD_RESTART_TRIGGER_MODE=1, MOD_RESTART_WELCOME_TIPS=true, MOD_RESTART_WELCOME_TIPS_TIME=6 &#125;, enabled=false &#125;&#125; workshop-[id] 此处ID即为创意工坊中连接的ID，可直接在创意工坊中查看；configuration_options配置选项同游戏中Mod配置相同，由于不清楚具体配置内容，不推荐手动修改。 那如何下载Mod呢？首先需要编辑文件： 1234567891011vim ~/dst/mods/dedicated_server_mods_setup.lua# 在文件中添加如下 : ( 括号中为 Mod 在创意工坊中的 id，内容按照自身服务器所需Mod填写 ) ServerModSetup(\"1216718131\")ServerModSetup(\"375850593\")ServerModSetup(\"378160973\")ServerModSetup(\"458587300\")ServerModSetup(\"703758203\")ServerModSetup(\"804317397\")ServerModSetup(\"1699254645\")# 保存退出# PS:此处还可以直接输入Mod合集，即ServerModCollectionSetup(\"[id]\") 配置过之后，下次启动游戏时就会自动下载Mod并启用。 7.启动游戏可以直接启动 ( 推荐使用脚本 ) : 12345cd ~/dst/bin# 启动地面世界./dontstarve_dedicated_server_nullrenderer -console -cluster MyDediServer -shard Master# 启动洞穴世界./dontstarve_dedicated_server_nullrenderer -console -cluster MyDediServer -shard Caves 编写启动脚本： 1234567891011121314151617181920212223mkdir ~/dst_scriptcd ~/dst_scripttouch dst_master.shtouch dst_caves.shchmod a+x dst_master.shchmod a+x dst_caves.sh# 编辑标本vim dst_master.sh# 输入#!/bin/bashcd ~/dst/binscreen -dmS \"dst_overworld\" ./dontstarve_dedicated_server_nullrenderer -console -cluster MyDediServer -shard Master# 保存退出vim dst_caves.sh# 输入#!/bin/bashcd ~/dst/binscreen -dmS \"dst_caves\" ./dontstarve_dedicated_server_nullrenderer -console -cluster MyDediServer -shard Caves# 保存退出 使用 screen -dmS 命令启动进程时，不会显示对应的控制台。如果需要使用控制台，则需要使用 123456# 恢复到地面世界进程screen -r dst_overworld# 隐藏控制台按下Ctrl+A然后按下Ctrl+D即可# 恢复到洞穴世界进程screen -r dst_caves# 隐藏控制台按下Ctrl+A然后按下Ctrl+D即可 启动游戏，运行脚本 12./dst_master.sh./dst_caves.sh 等服务器启动后，即可在大厅搜索到对应服务器。 8.关于更新编写更新脚本 123touch ~/dst_script/update.shchmod a+x ~/dst_script/update.shvim ~/dst_script/update.sh 输入 12345678#!/bin/bash#更新游戏~/steamcmd/steamcmd.sh +login anonymous +force_install_dir /home/steam/dst +app_update 343050 validate +quit#更新modcd /home/steam/dst/bin~/dst/bin/dontstarve_dedicated_server_nullrenderer -only_update_server_mods 执行时需要关闭服务器。 饥荒的游戏存档位置默认为 ~/.kiel/DoNotStarveTogether/中，上面我们启动命令中指定了-cluster的参数，游戏就会再上述文件夹中创建一个名为MyDediServer的文件夹，若不指定该参数，默认创建Cluster_1。","categories":[{"name":"游戏服务器","slug":"游戏服务器","permalink":"https://39.97.115.194/categories/游戏服务器/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://39.97.115.194/tags/Linux/"},{"name":"饥荒","slug":"饥荒","permalink":"https://39.97.115.194/tags/饥荒/"},{"name":"专用服务器","slug":"专用服务器","permalink":"https://39.97.115.194/tags/专用服务器/"},{"name":"Shell","slug":"Shell","permalink":"https://39.97.115.194/tags/Shell/"},{"name":"阿里云","slug":"阿里云","permalink":"https://39.97.115.194/tags/阿里云/"}]},{"title":"生成Excel和CSV的工具类","slug":"生成Excel和CSV的工具类","date":"2019-01-21T01:12:00.000Z","updated":"2019-05-15T08:12:25.023Z","comments":true,"path":"2019/01/21/生成Excel和CSV的工具类/","link":"","permalink":"https://39.97.115.194/2019/01/21/生成Excel和CSV的工具类/","excerpt":"使用Java编写的生成Excel和CSV的工具类。","text":"使用Java编写的生成Excel和CSV的工具类。 由于数据量过大时，生成Excel速度很慢，过程中内存占用量很大。因此当数据条数大于10000时，不支持生成Excel文件，并且使用CopyManager（postgresql中的工具）来生成CSV文件。 利用查询后的结果生成Excel和CSV文件的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206import com.unicom.simpledemo.dao.UserDefinedSQLMapper;import lombok.extern.slf4j.Slf4j;import org.apache.poi.ss.usermodel.CellStyle;import org.apache.poi.ss.usermodel.HorizontalAlignment;import org.apache.poi.xssf.streaming.SXSSFCell;import org.apache.poi.xssf.streaming.SXSSFRow;import org.apache.poi.xssf.streaming.SXSSFSheet;import org.apache.poi.xssf.streaming.SXSSFWorkbook;import org.postgresql.copy.CopyManager;import org.postgresql.core.BaseConnection;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.*;import java.sql.Connection;import java.sql.DriverManager;import java.util.*;/** * Author by BayMin, Date on 2018/11/15. */@Slf4j@Componentpublic class ExportUtils &#123; private static String driverClass; private static String dbUrl; private static String dbUserName; private static String dbPassword; @Value(\"$&#123;spring.datasource.druid.driver-class-name&#125;\") public void setDriverClass(String str) &#123; driverClass = str; &#125; @Value(\"$&#123;spring.datasource.druid.url&#125;\") public void setDbUrl(String str) &#123; dbUrl = str; &#125; @Value(\"$&#123;spring.datasource.druid.username&#125;\") public void setDbUserName(String str) &#123; dbUserName = str; &#125; @Value(\"$&#123;spring.datasource.druid.password&#125;\") public void setDbPassword(String str) &#123; dbPassword = str; &#125; /** * 根据查询结果生成Excel * * @return 生成的Excel */ @SuppressWarnings(\"unchecked\") public static SXSSFWorkbook mapListToExcel(HttpSession session, UserDefinedSQLMapper userDefinedSQLMapper) &#123; List&lt;LinkedHashMap&lt;String, Object&gt;&gt; linkedHashMaps = null; int rows = (int) session.getAttribute(\"rows\"); if (rows &gt;= 10000) &#123; log.error(\"行数为\" + rows + \"，不小于10000行，无法导出为Excel表格！\"); return null; &#125; linkedHashMaps = (List&lt;LinkedHashMap&lt;String, Object&gt;&gt;) session.getAttribute(\"linkedHashMaps\"); log.info(\"正在生成Excel表格...\"); SXSSFWorkbook workbook = new SXSSFWorkbook(100); SXSSFSheet sheet = workbook.createSheet(\"result\"); SXSSFRow row = sheet.createRow(0); CellStyle style = workbook.createCellStyle(); style.setAlignment(HorizontalAlignment.CENTER); LinkedList&lt;String&gt; keys = (LinkedList&lt;String&gt;) session.getAttribute(\"keys\"); int columnNum = keys.size(); for (int i = 0; i &lt; columnNum; i++) &#123; SXSSFCell cell = row.createCell(i); cell.setCellValue(keys.get(i)); cell.setCellStyle(style); sheet.trackAllColumnsForAutoSizing(); sheet.autoSizeColumn(i); &#125; for (int i = 0; i &lt; linkedHashMaps.size(); i++) &#123; row = sheet.createRow(i + 1); if (linkedHashMaps.get(i) != null) &#123; Iterator&lt;Map.Entry&lt;String, Object&gt;&gt; iterator = linkedHashMaps.get(i).entrySet().iterator(); int j = 0; while (iterator.hasNext()) &#123; Map.Entry&lt;String, Object&gt; next = iterator.next(); if (next.getValue() != null) &#123; row.createCell(j++).setCellValue(next.getValue().toString()); &#125; else &#123; row.createCell(j++).setCellValue(\"\"); &#125; &#125; &#125; else &#123; row.createCell(0).setCellValue(\"\"); &#125; &#125; log.info(\"生成Excel表格完成！\"); return workbook; &#125; /** * 导出Excel * * @param workbook 需要导出的Excel */ public static void exportExcel(HttpServletRequest request, HttpServletResponse response, SXSSFWorkbook workbook) &#123; response.setContentType(\"application/vnd.ms-excel\"); response.setHeader(\"Content-disposition\", \"attachment;filename=Table-\" + Utils.parseDate(new Date()) + \".xlsx\"); try &#123; OutputStream outputStream = response.getOutputStream(); workbook.write(outputStream); outputStream.flush(); outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 导出CSV文件 * * @param session session(其中包含sql) */ @SuppressWarnings(\"unchecked\") public static void exportCSV(HttpServletRequest request, HttpServletResponse response, HttpSession session) &#123; LinkedList&lt;String&gt; keys = (LinkedList&lt;String&gt;) session.getAttribute(\"keys\"); StringBuilder tableHead = new StringBuilder(); for (String str : keys) &#123; tableHead.append(str).append(\",\"); &#125; String headString = tableHead.substring(0, tableHead.length() - 1); headString = headString.concat(\"\\n\"); try &#123; response.setContentType(\"text/csv\"); response.setHeader(\"Content-disposition\", \"attachment;filename=Table-\" + Utils.parseDate(new Date()) + \".csv\"); OutputStream outputStream = response.getOutputStream(); if ((int) session.getAttribute(\"rows\") &gt;= 10000) &#123; exportCSVBySQL(request, response, session, headString, outputStream); &#125; else &#123; exportCSVBySession(request, response, session, headString, outputStream); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @SuppressWarnings(\"unchecked\") private static void exportCSVBySession(HttpServletRequest request, HttpServletResponse response, HttpSession session, String headString, OutputStream outputStream) &#123; StringBuilder stringBuilder = new StringBuilder(headString); String csv = \"\"; List&lt;LinkedHashMap&lt;String, Object&gt;&gt; linkedHashMapsTop500 = (List&lt;LinkedHashMap&lt;String, Object&gt;&gt;) session.getAttribute(\"linkedHashMaps\"); for (LinkedHashMap&lt;String, Object&gt; linkedHashMap : linkedHashMapsTop500) &#123; for (Map.Entry&lt;String, Object&gt; next : linkedHashMap.entrySet()) &#123; if (next.getValue() != null) &#123; stringBuilder.append(next.getValue().toString()); &#125; stringBuilder.append(\",\"); &#125; stringBuilder.deleteCharAt(stringBuilder.length() - 1).append(\"\\n\"); &#125; csv = stringBuilder.substring(0, stringBuilder.length() - 1); outputStreamWrite(csv, outputStream); try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static void exportCSVBySQL(HttpServletRequest request, HttpServletResponse response, HttpSession session, String headString, OutputStream outputStream) &#123; outputStreamWrite(headString, outputStream); String sql = session.getAttribute(\"sql\").toString(); try &#123; Class.forName(driverClass); Connection connection = DriverManager.getConnection(dbUrl, dbUserName, dbPassword); CopyManager copyManager = new CopyManager((BaseConnection) connection); copyManager.copyOut(\"copy (\" + sql + \") to stdout with csv\", outputStream); outputStream.flush(); outputStream.close(); &#125; catch (Exception e) &#123; log.error(\"使用COPY命令导出CSV文件出错，当前SQL为：\" + sql); e.printStackTrace(); &#125; &#125; private static void outputStreamWrite(String info, OutputStream outputStream) &#123; byte[] bytes = info.getBytes(); InputStream inputStream = new ByteArrayInputStream(bytes); byte[] buff = new byte[1024]; int len; try &#123; while ((len = inputStream.read(buff)) != -1) &#123; outputStream.write(buff, 0, len); outputStream.flush(); &#125; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://39.97.115.194/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://39.97.115.194/tags/Java/"},{"name":"工具类","slug":"工具类","permalink":"https://39.97.115.194/tags/工具类/"}]},{"title":"Greenplum数据库迁移","slug":"Greenplum数据库迁移","date":"2018-12-12T00:20:00.000Z","updated":"2019-05-13T08:15:43.238Z","comments":true,"path":"2018/12/12/Greenplum数据库迁移/","link":"","permalink":"https://39.97.115.194/2018/12/12/Greenplum数据库迁移/","excerpt":"由于之前的数据库使用年限过久，机器性能无法满足日常计算需要，因此公司最近新购入了若干服务器，并准备将数据迁移至新库中。在正式迁移之前，通过查阅相关资料，进行一次模拟迁移。","text":"由于之前的数据库使用年限过久，机器性能无法满足日常计算需要，因此公司最近新购入了若干服务器，并准备将数据迁移至新库中。在正式迁移之前，通过查阅相关资料，进行一次模拟迁移。 1.准备① VMware Workstation软件 ② CentOS 7.3 镜像 ( 与老服务器相同 ) ③ Greenplum 4.3.7.3 安装包 ( https://network.pivotal.io/products/pivotal-gpdb/ ) 2.安装虚拟机修改时区，最小安装： 添加root用户密码： 安装完成后，修改IP地址： 1vi /etc/sysconfig/netword-scripts/ifcfg-eno*** 123456789101112131415161718192021TYPE=EthernetBOOTPROTO=staticDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=eno16777736UUID=5bed79bf-0f21-40fe-a92c-63aa29d0dbddDEVICE=eno16777736ONBOOT=yesIPADDR=192.168.216.128NETMASK=255.255.255.0GATEWAY=192.168.216.2DNS1=114.114.114.114DNS2=8.8.8.8 重启network服务，并使用ping测试是否可以连接到外网： 1service network restart 安装一些需要的工具： 1yum -y install vim net-tools ntp ed unzip 设置开机时间同步脚本： 1vim /etc/rc.d/init.d/timelock.sh 12345678910#!/bin/bash##Startup script for timelock##chkconfig:345 85 15#description:timelock server#processname:timelock #Source function library./usr/sbin/ntpdate -u ntp1.aliyun.com 增加脚本的可执行权限并添加到开机启动项目中： 1234chmod a+x /etc/rc.d/init.d/autostart.shcd /etc/rc.d/init.dchkconfig --add autostart.shchkconfig autostart.sh on 修改系统内核 ( Greenplum需要 )： 1vim /etc.sysctl.conf 12345678910111213141516171819kernel.shmmax = 500000000kernel.shmmni = 4096kernel.shmall = 4000000000kernel.sem = 250 512000 100 2048kernel.sysrq = 1kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.msgmni = 2048net.ipv4.tcp_syncookies = 1net.ipv4.ip_forward = 0net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.conf.all.arp_filter = 1net.ipv4.ip_local_port_range = 1025 65535net.core.netdev_max_backlog = 10000net.core.rmem_max = 2097152net.core.wmem_max = 209715 打开文件限制 : ( 在最后添加 ) 1vim /etc/security/limits.conf 1234* soft nofile 65536* hard nofile 65536* soft nproc 131072* hard nproc 131072 创建gpadmin用户和用户组 ( 每台都需要配置 ) ： 123groupadd -g 530 gpadminuseradd -g 530 -u530 -m -d /home/gpadmin -s /bin/bash gpadminpasswd gpadmin 关闭防火墙： 12systemctl stop firewalld.servicesystemctl disable firewalld.service 3.拷贝两份虚拟机分别修改IP、hostname，配置hosts 1234567192.168.216.128 Master master192.168.216.129 sdw1192.168.216.130 sdw2 192.168.216.138 Master_standby master_standby gp_master_standby192.168.216.139 sdw1_standby segment_standby segment192.168.216.140 sdw2_standby mirror_standby mirror 重启，准备安装数据库。 4.安装数据库首先在Master节点上操作： ​ 切换用户gpadmin，解压下载的数据库文件并运行greenplum-db-*.bin安装文件 ( 安装过程中注意数据库安装位置 ) 创建配置文件： 1mkdir ./conf 1vim ./conf/hostlist 123Master_standbysdw1_standbysdw2_standby 1vim ./conf/set_host 12sdw1_standbysdw2_standby 引入Greenplum的环境变量： 1source ./greenplum-db-4.3.7.3/greenplum_path.sh 交换钥匙： 1gpssh-exkeys -f ./conf/hostlist PS： 一个小问题 socket.gaierror: [Errno -2] Name or service not known 1原因 hosts 里没有配置 hostname 中的 IP 开始安装数据库： 1gpseginstall -f hostlist -u gpadmin -p 123456 在不同节点上创建数据目录： 1234567891011121314#gp_master_standby:mkdir -p /home/gpadmin/gpdata/gpmaster#sdw1_standby:mkdir -p /home/gpadmin/gpdata/gpdata1mkdir -p /home/gpadmin/gpdata/gpdatap1mkdir -p /home/gpadmin/gpdata/gpdatap2mkdir -p /home/gpadmin/gpdata/gpdatam1mkdir -p /home/gpadmin/gpdata/gpdatam2#sdw2_standbymkdir -p /home/gpadmin/gpdata/gpmastermkdir -p /home/gpadmin/gpdata/gpdatap1mkdir -p /home/gpadmin/gpdata/gpdatap2mkdir -p /home/gpadmin/gpdata/gpdatam1mkdir -p /home/gpadmin/gpdata/gpdatam2 检查系统环境： 12#错误暂且不管 ( 好像并没有影响 )gpcheck -f ./conf/hostlist -m Master_standby -s sdw2_standby 编写初始化文件： 1234567891011121314151617181920212223#数据库代号ARRAY_NAME=\"EMC Greenplum DW\"MACHINE_LIST_FILE=/home/gpadmin/conf/seg_hosts#Segment 的名称前缀SEG_PREFIX=gpseg#primary segment 起始端口号PORT_BASE=40000#指定 primary segment 的数据目录declare -a DATA_DIRECTORY=(/home/gpadmin/gpdata/gpdatap1 /home/gpadmin/gpdata/gpdatap2)MASTER_HOSTNAME=gp_master_standbyMASTER_DIRECTORY=/home/gpadmin/gpdata/gpmasterMASTER_DATA_DIRECTORY=/home/gpadmin/gpdata/gpmasterMASTER_PORT=5432#指定 bash 的版本TRUSTED_SHELL=ssh#mirror segment 起始端口号MIRROR_PORT_BASE=50000#primary segment 主备同步的起始端口号REPLICATION_PORT_BASE=41000#mirror segment 主备同步的起始端口号MIRROR_REPLICATION_PORT_BASE=51000#mirror segment 的数据目录declare -a MIRROR_DATA_DIRECTORY=(/home/gpadmin/gpdata/gpdatam1 /home/gpadmin/gpdata/gpdatam2) 初始化数据库： 1gpinitsystem -c ./conf/gp_init_config -s sdw2_standby 启动数据库 : 1gpstart -a 至此，数据库安装完毕，准备迁移数据。 5.迁移数据库Greenplum数据库迁移可以使用官方自带工具gptransfer进行迁移，具体使用方法参照官网 ( https://gp-docs-cn.github.io/docs/best_practices/gptransfer.html) 修改源数据库中配置文件： 1vim /home/gpadmin/gpdata/gpmaster/gpseg-1/pg_hba.conf 添加如下 ( IP范围为192.168.216.1 - 192.168.216.254 ) ： 1host all all 192.168.216.1/24 md5 在源数据库中重新加载配置文件： 1select pg_reload_conf() 准备打通目标数据库与源数据库之间的通道，创建映射文件： 1vim ./conf/transferlist 12sdw1,192.168.216.129sdw2,192.168.216.130 1vim ./conf/transhost 12345sdw2_standbysdw1_standbymastersdw1sdw2 交换钥匙： 1gpssh-exkeys -f /home/gpadmin/conf/transhost 开始迁移数据： 1/home/gpadmin/greenplum-db-4.3.7.3/bin//gptransfer --source-map-file=/home/gpadmin/conf/transferlist --dest-host=192.168.216.128 --full 迁移完毕： 将源数据库中的配置文件postgresql.conf和pg_hba.conf发送至目标数据库中，重启目标数据库。 至此数据库迁移完毕。 参考网址① https://gp-docs-cn.github.io/docs/best_practices/gptransfer.html ② https://www.cnblogs.com/liuyungao/p/5689588.html","categories":[{"name":"Greenplum","slug":"Greenplum","permalink":"https://39.97.115.194/categories/Greenplum/"}],"tags":[{"name":"Greenplum","slug":"Greenplum","permalink":"https://39.97.115.194/tags/Greenplum/"},{"name":"数据库","slug":"数据库","permalink":"https://39.97.115.194/tags/数据库/"},{"name":"数据迁移","slug":"数据迁移","permalink":"https://39.97.115.194/tags/数据迁移/"}]},{"title":"Greenplum查看数据库和表所占磁盘大小","slug":"Greenplum查看数据库和表所占磁盘大小","date":"2018-12-05T07:37:00.000Z","updated":"2019-05-15T07:53:00.250Z","comments":true,"path":"2018/12/05/Greenplum查看数据库和表所占磁盘大小/","link":"","permalink":"https://39.97.115.194/2018/12/05/Greenplum查看数据库和表所占磁盘大小/","excerpt":"查看数据库所占磁盘大小的几条命令。","text":"查看数据库所占磁盘大小的几条命令。 表的大小 : 12345select pg_size_pretty(pg_relation_size('gp_test')); pg_size_pretty ---------------- 1761 MB(1 row) 表和索引的大小 : 12345select pg_size_pretty(pg_total_relation_size('gp_test')); pg_size_pretty ---------------- 2186 MB(1 row) 查看指定数据库大小 : 12345select pg_size_pretty(pg_database_size('zwcdb')); pg_size_pretty ---------------- 2241 MB(1 row) 查看所有数据库的大小 : 123456789select datname,pg_size_pretty(pg_database_size(datname)) from pg_database; datname | pg_size_pretty -----------+---------------- zwcdb | 2241 MB postgres | 47 MB template1 | 47 MB template0 | 45 MB gpperfmon | 67 MB(5 rows) 查看数据分布情况和磁盘空间 : 12345678910111213141516select gp_segment_id,count(*) from gp_test group by gp_segment_id order by 1; gp_segment_id | count ---------------+--------- 0 | 5000000 1 | 4999999 2 | 5000001 3 | 5000000(4 rows) select dfhostname, dfspace,dfdevice from gp_toolkit.gp_disk_free order by dfhostname; dfhostname | dfspace | dfdevice ------------+----------+------------ sdw1 | 12273372 | /dev/sdb1 sdw1 | 12273372 | /dev/sdb1 sdw2 | 12273404 | /dev/sdb1 sdw2 | 12273404 | /dev/sdb1","categories":[{"name":"Greenplum","slug":"Greenplum","permalink":"https://39.97.115.194/categories/Greenplum/"}],"tags":[{"name":"Greenplum","slug":"Greenplum","permalink":"https://39.97.115.194/tags/Greenplum/"},{"name":"数据库","slug":"数据库","permalink":"https://39.97.115.194/tags/数据库/"}]}]}